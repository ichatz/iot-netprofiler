{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1080cfd9cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "#Modules to install via pip pandas,ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import import_ipynb\n",
    "import sys\n",
    "import kmeans\n",
    "sys.path.append('../')\n",
    "from functions import *\n",
    "from lib.trace_analysis import *\n",
    "from plots import *\n",
    "from lib.trace_analysis_cooja2 import *\n",
    "from node import *\n",
    "from lib.plots_analysis import *\n",
    "from pandas.plotting import scatter_matrix\n",
    "import cmath as math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "# scipy\n",
    "from scipy.cluster.vq import kmeans,vq,whiten\n",
    "import sklearn.metrics as sm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import random\n",
    "random.seed(6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "        type  packet loss\n",
      "0         BH    91.666667\n",
      "1         BH   100.000000\n",
      "2         BH   100.000000\n",
      "3         BH   100.000000\n",
      "4         BH   100.000000\n",
      "5         BH   100.000000\n",
      "6         BH   100.000000\n",
      "7         BH   100.000000\n",
      "8         BH   100.000000\n",
      "9         BH   100.000000\n",
      "10        BH   100.000000\n",
      "11        BH   100.000000\n",
      "12        BH   100.000000\n",
      "13        BH   100.000000\n",
      "14        BH   100.000000\n",
      "15        BH   100.000000\n",
      "16        BH   100.000000\n",
      "17        BH    91.666667\n",
      "18        BH   100.000000\n",
      "19        BH   100.000000\n",
      "20        BH   100.000000\n",
      "21        BH   100.000000\n",
      "22        BH   100.000000\n",
      "23        BH   100.000000\n",
      "24        BH   100.000000\n",
      "25        BH   100.000000\n",
      "26        BH   100.000000\n",
      "27        BH   100.000000\n",
      "28        BH   100.000000\n",
      "29        BH   100.000000\n",
      "...      ...          ...\n",
      "1959  normal     0.000000\n",
      "1960  normal     0.000000\n",
      "1961  normal     0.000000\n",
      "1962  normal     0.000000\n",
      "1963  normal     0.000000\n",
      "1964  normal     0.000000\n",
      "1965  normal     0.000000\n",
      "1966  normal     0.000000\n",
      "1967  normal     0.000000\n",
      "1968  normal     8.333333\n",
      "1969  normal     0.000000\n",
      "1970  normal     0.000000\n",
      "1971  normal    25.000000\n",
      "1972  normal     8.333333\n",
      "1973  normal     0.000000\n",
      "1974  normal     0.000000\n",
      "1975  normal     0.000000\n",
      "1976  normal    16.666667\n",
      "1977  normal     0.000000\n",
      "1978  normal     0.000000\n",
      "1979  normal     0.000000\n",
      "1980  normal     0.000000\n",
      "1981  normal     0.000000\n",
      "1982  normal     8.333333\n",
      "1983  normal     0.000000\n",
      "1984  normal     0.000000\n",
      "1985  normal     0.000000\n",
      "1986  normal     0.000000\n",
      "1987  normal     0.000000\n",
      "1988  normal    33.333333\n",
      "\n",
      "[1989 rows x 2 columns]\n",
      "[0 0 0 ... 1 1 1]\n",
      "0.45701357466063347\n",
      "[0 0 0 ... 1 1 1]\n",
      "array([[ 484, 1046],\n",
      "       [  34,  425]])\n",
      "                              case                   predicted    real\n",
      "0    grid9_1bh-3_2019-02-13_16:28_  10.457516339869281% normal      BH\n",
      "1    grid9_1bh-3_2019-02-13_22:05_   11.11111111111111% normal      BH\n",
      "2    grid9_1bh-5_2019-02-13_15:31_   90.19607843137256% normal      BH\n",
      "3    grid9_1bh-5_2019-02-13_21:44_   90.19607843137256% normal      BH\n",
      "4    grid9_1bh-6_2019-02-13_12:59_    80.3921568627451% normal      BH\n",
      "5    grid9_1bh-6_2019-02-13_19:15_  62.091503267973856% normal      BH\n",
      "6    grid9_1bh-7_2019-02-13_15:08_   86.27450980392157% normal      BH\n",
      "7    grid9_1bh-7_2019-02-13_20:02_   75.81699346405229% normal      BH\n",
      "8    grid9_1bh-9_2019-02-13_15:57_   95.42483660130719% normal      BH\n",
      "9    grid9_1bh-9_2019-02-13_19:35_   81.69934640522875% normal      BH\n",
      "10  grid9_normal_2019-02-13_17:05_   81.69934640522875% normal  normal\n",
      "11  grid9_normal_2019-02-13_18:51_    98.0392156862745% normal  normal\n",
      "12  grid9_normal_2019-02-13_22:23_    98.0392156862745% normal  normal\n"
     ]
    }
   ],
   "source": [
    "#directory=os.getcwd()+\"/cooja3-9nodes/\"\n",
    "directory=\"../cooja3-9nodes/\"\n",
    "plots = [\n",
    "        #2 BH3\n",
    "        (directory+\"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_16:28_',\"BH\"),\n",
    "        (directory+\"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_22:05_',\"BH\"),\n",
    "        #2 BH5\n",
    "         (directory+\"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_15:31_',\"BH\"),\n",
    "          (directory+\"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_21:44_',\"BH\"),\n",
    "        #2 BH 6\n",
    "        (directory+\"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_12:59_',\"BH\"),\n",
    "        (directory+\"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_19:15_',\"BH\"),\n",
    "        #2 BH 7\n",
    "         (directory+\"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_15:08_',\"BH\"),\n",
    "         (directory+\"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_20:02_',\"BH\"),\n",
    "         #2 bh 9\n",
    "         (directory+\"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_15:57_',\"BH\"),\n",
    "         (directory+\"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_19:35_',\"BH\"),\n",
    "         #3 normal\n",
    "         (directory+\"traces/normal\", 'grid9_normal_2019-02-13_17:05_',\"normal\"),\n",
    "         (directory+\"traces/normal\",  \"grid9_normal_2019-02-13_18:51_\",\"normal\"),\n",
    "         (directory+\"traces/normal\",  \"grid9_normal_2019-02-13_22:23_\",\"normal\"),\n",
    "        ]\n",
    "\n",
    "analyze_network(directory,plots,200,12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"../cooja3-9nodes/\"\n",
    "plots = [\n",
    "        #2 BH3\n",
    "        ( \"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_16:28_',\"BH\"),\n",
    "        ( \"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_22:05_',\"BH\"),\n",
    "        #2 BH5\n",
    "         ( \"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_15:31_',\"BH\"),\n",
    "          ( \"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_21:44_',\"BH\"),\n",
    "        #2 BH 6\n",
    "        ( \"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_12:59_',\"BH\"),\n",
    "        ( \"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_19:15_',\"BH\"),\n",
    "        #2 BH 7\n",
    "         ( \"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_15:08_',\"BH\"),\n",
    "         ( \"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_20:02_',\"BH\"),\n",
    "         #2 bh 9\n",
    "         ( \"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_15:57_',\"BH\"),\n",
    "         ( \"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_19:35_',\"BH\"),\n",
    "         #3 normal\n",
    "         ( \"traces/normal\", 'grid9_normal_2019-02-13_17:05_',\"normal\"),\n",
    "         ( \"traces/normal\",  \"grid9_normal_2019-02-13_18:51_\",\"normal\"),\n",
    "         ( \"traces/normal\",  \"grid9_normal_2019-02-13_22:23_\",\"normal\"),\n",
    "        ]\n",
    "\n",
    "d= {\n",
    "    \"directory\":[],\n",
    "    \"case\":[],\n",
    "    \"case_accuracy\":[]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in plots:\n",
    "#     d[\"directory\"].append(i[0])\n",
    "#     d[\"case\"].append(i[1])\n",
    "#     d[\"case_accuracy\"].append(i[2])\n",
    "# df=pd.DataFrame(d)\n",
    "# df.to_csv(\"traces.csv\", sep='', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grid9_1bh-3_2019-02-13_16:28_' 'grid9_1bh-3_2019-02-13_22:05_'\n",
      " 'grid9_1bh-5_2019-02-13_15:31_' 'grid9_1bh-5_2019-02-13_21:44_'\n",
      " 'grid9_1bh-6_2019-02-13_12:59_' 'grid9_1bh-6_2019-02-13_19:15_'\n",
      " 'grid9_1bh-7_2019-02-13_15:08_' 'grid9_1bh-7_2019-02-13_20:02_'\n",
      " 'grid9_1bh-9_2019-02-13_15:57_' 'grid9_1bh-9_2019-02-13_19:35_'\n",
      " 'grid9_normal_2019-02-13_17:05_' 'grid9_normal_2019-02-13_18:51_'\n",
      " 'grid9_normal_2019-02-13_22:23_' 'rnd_1bh-2_2019-02-14_15:38_'\n",
      " 'rnd_1bh-7_2019-02-14_13:57_' 'rnd_1bh-9_2019-02-14_15:15_'\n",
      " 'rnd_normal_2019-02-14_13:37_']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>case</th>\n",
       "      <th>case_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traces/1bh-3</td>\n",
       "      <td>grid9_1bh-3_2019-02-13_16:28_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traces/1bh-3</td>\n",
       "      <td>grid9_1bh-3_2019-02-13_22:05_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traces/1bh-5</td>\n",
       "      <td>grid9_1bh-5_2019-02-13_15:31_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traces/1bh-5</td>\n",
       "      <td>grid9_1bh-5_2019-02-13_21:44_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traces/1bh-6</td>\n",
       "      <td>grid9_1bh-6_2019-02-13_12:59_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>traces/1bh-6</td>\n",
       "      <td>grid9_1bh-6_2019-02-13_19:15_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>traces/1bh-7</td>\n",
       "      <td>grid9_1bh-7_2019-02-13_15:08_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>traces/1bh-7</td>\n",
       "      <td>grid9_1bh-7_2019-02-13_20:02_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>traces/1bh-9</td>\n",
       "      <td>grid9_1bh-9_2019-02-13_15:57_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>traces/1bh-9</td>\n",
       "      <td>grid9_1bh-9_2019-02-13_19:35_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>traces/normal</td>\n",
       "      <td>grid9_normal_2019-02-13_17:05_</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>traces/normal</td>\n",
       "      <td>grid9_normal_2019-02-13_18:51_</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>traces/normal</td>\n",
       "      <td>grid9_normal_2019-02-13_22:23_</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>traces/rnd-1</td>\n",
       "      <td>rnd_1bh-2_2019-02-14_15:38_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>traces/rnd-1</td>\n",
       "      <td>rnd_1bh-7_2019-02-14_13:57_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traces/rnd-1</td>\n",
       "      <td>rnd_1bh-9_2019-02-14_15:15_</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>traces/rnd-1</td>\n",
       "      <td>rnd_normal_2019-02-14_13:37_</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        directory                            case case_accuracy\n",
       "0    traces/1bh-3   grid9_1bh-3_2019-02-13_16:28_            BH\n",
       "1    traces/1bh-3   grid9_1bh-3_2019-02-13_22:05_            BH\n",
       "2    traces/1bh-5   grid9_1bh-5_2019-02-13_15:31_            BH\n",
       "3    traces/1bh-5   grid9_1bh-5_2019-02-13_21:44_            BH\n",
       "4    traces/1bh-6   grid9_1bh-6_2019-02-13_12:59_            BH\n",
       "5    traces/1bh-6   grid9_1bh-6_2019-02-13_19:15_            BH\n",
       "6    traces/1bh-7   grid9_1bh-7_2019-02-13_15:08_            BH\n",
       "7    traces/1bh-7   grid9_1bh-7_2019-02-13_20:02_            BH\n",
       "8    traces/1bh-9   grid9_1bh-9_2019-02-13_15:57_            BH\n",
       "9    traces/1bh-9   grid9_1bh-9_2019-02-13_19:35_            BH\n",
       "10  traces/normal  grid9_normal_2019-02-13_17:05_        normal\n",
       "11  traces/normal  grid9_normal_2019-02-13_18:51_        normal\n",
       "12  traces/normal  grid9_normal_2019-02-13_22:23_        normal\n",
       "13   traces/rnd-1     rnd_1bh-2_2019-02-14_15:38_            BH\n",
       "14   traces/rnd-1     rnd_1bh-7_2019-02-14_13:57_            BH\n",
       "15   traces/rnd-1     rnd_1bh-9_2019-02-14_15:15_            BH\n",
       "16   traces/rnd-1    rnd_normal_2019-02-14_13:37_        normal"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory='../cooja3-9nodes/traces/traces.csv'\n",
    "df=pd.read_csv(directory, sep=',', encoding='utf-8')\n",
    "\n",
    "col=df[\"case\"].values\n",
    "print(col)\n",
    "#for i in range(len(df)):\n",
    "    #print(i)\n",
    "    #print(df)\n",
    "    #col=df[\"cases\"]\n",
    "df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_nodes_Cooja_2(directory,tracemask,node_defaults):\n",
    "    #print(directory)\n",
    "    #print(tracemask)\n",
    "    files = []\n",
    "\n",
    "    # load all files and extract IPs of nodes\n",
    "    for file in os.listdir(directory):\n",
    "        try:\n",
    "            if file.startswith(tracemask) and file.index(\"routes\"):\n",
    "                continue\n",
    "        except:\n",
    "            files.append(file)\n",
    "\n",
    "    nodes = pd.DataFrame(columns=['node_id', 'rank'])\n",
    "    packets_node = {}\n",
    "\n",
    "    # Load the ICMP traces\n",
    "    for file in files:\n",
    "        packets = pd.read_csv(directory + '/' + file,\n",
    "                              sep=' |icmp_seq=|ttl=|time=',\n",
    "                              na_filter=True,\n",
    "                              header=None,\n",
    "                              skiprows=1,\n",
    "                              skipfooter=4,\n",
    "                              usecols=[3, 5, 7, 9],\n",
    "                              names=['node_id', 'seq', 'hop', 'rtt'],\n",
    "                              engine='python').dropna().drop_duplicates()\n",
    "\n",
    "        if len(packets) < 1:\n",
    "            # Nodes affected by a black hole did not receive any packet\n",
    "            node_id = file[-24:-4]\n",
    "            packets = pd.DataFrame(columns=['node_id', 'seq', 'hop', 'rtt'],\n",
    "                                   data=[[node_id, 1, node_defaults[node_id], 1]])\n",
    "\n",
    "            nodes.loc[len(nodes)] = [file[-24:-4], node_defaults[node_id]]\n",
    "            packets_node[file[-24:-4]] = packets\n",
    "\n",
    "        else:\n",
    "            #print(\"qui\")\n",
    "            packets['node_id'] = packets.apply(lambda row: row['node_id'][:-1], axis=1)\n",
    "            #print(packets[\"hop\"].head())\n",
    "            #print(nodes)\n",
    "            #nodes.loc[len(nodes)-1] = [packets['node_id'][0], 64-packets['hop'][0]]\n",
    "            #print(\"ciao\"+ str(64-packets['hop'][0]))\n",
    "            #print(nodes.loc[7])\n",
    "            packets = packets.sort_values(by=['node_id', 'seq'], ascending=True, na_position='first')\n",
    "            packets = packets[packets['rtt'] > 1]\n",
    "            packets[\"hop\"]=  64-packets['hop']\n",
    "            packets_node[packets['node_id'][0]] = packets\n",
    "\n",
    "    nodes=nodes.sort_values(by=['rank', 'node_id'])\n",
    "\n",
    "    #tranformation in node\n",
    "    nodeList=[]\n",
    "\n",
    "    for n in packets_node.keys():\n",
    "        #print((packets_node[n]).head())\n",
    "        pkts=packets_node[n].drop([\"node_id\",\"hop\"],axis=1)\n",
    "        #print(pkts)\n",
    "        hop=int(packets_node[n][\"hop\"][0])\n",
    "        ip=packets_node[n][\"node_id\"][0]\n",
    "        #print(hop)\n",
    "        n=node(ip,hop,pkts)\n",
    "        nodeList.append(n)\n",
    "\n",
    "\n",
    "    return nodeList\n",
    "\n",
    "\n",
    "def import_Cooja2(df):\n",
    "    data=[]\n",
    "    node_defaults = {\n",
    "        \"aaaa::212:7403:3:303\": 1,\n",
    "        \"aaaa::212:7402:2:202\": 2,\n",
    "        \"aaaa::212:7404:4:404\": 2,\n",
    "        \"aaaa::212:7406:6:606\": 2,\n",
    "        \"aaaa::212:7405:5:505\": 3,\n",
    "        \"aaaa::212:7407:7:707\": 3,\n",
    "        \"aaaa::212:7409:9:909\": 3,\n",
    "        \"aaaa::212:7408:8:808\": 4,\n",
    "        \"aaaa::212:740a:a:a0a\": 4}\n",
    "    #for row in plots:\n",
    "\n",
    "        #print(\"Importing ./\"+row[0]+\"/\"+row[1])\n",
    "    print(directory+df[\"directory\"].values)\n",
    "    \n",
    "    for i in range(len(df[\"directory\"].values)):\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        nodeList=import_nodes_Cooja_2(directory+df[\"directory\"].values[i],df[\"case\"].values[i],node_defaults)\n",
    "        data.append(nodeList)\n",
    "    print(len(data))\n",
    "    print(len(data[0]))\n",
    "    return data\n",
    "\n",
    "def analyze_network(directory,df,pings,window):\n",
    "    cases=[]\n",
    "    casesAccuracy=df[\"case_accuracy\"].values\n",
    "#     for row in plots:\n",
    "#         cases.append(row[1])\n",
    "#         casesAccuracy.append(row[2])\n",
    "#         data=import_Cooja2(plots)\n",
    "    cases=df[\"case\"].values\n",
    "    folder=df[\"directory\"].values+directory\n",
    "    \n",
    "    data=import_Cooja2(df)\n",
    "    \n",
    "    #pings=getPings(data)\n",
    "    #All data collection is in variable node that is a list of list of nodes\n",
    "    #3 nets input x 9 nodes by net\n",
    "    print(\"Processing...\")\n",
    "    d={ \"label\":[],\n",
    "       \"type\":[],\n",
    "        \"count\":[],\n",
    "        \"std\":  [],\n",
    "        \"mean\": [],\n",
    "        \"var\":  [],\n",
    "        \"hop\":[],\n",
    "\n",
    "       \"packet loss\":[],\n",
    "       \"outliers\":[],\n",
    "       \"node\":[]\n",
    "    }\n",
    "    #count=[]\n",
    "    labels=[]\n",
    "    var=[]\n",
    "    #window=100\n",
    "    #stats=pd.DataFrame(columns=columns)\n",
    "    n=pings\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        #window=pings[i]\n",
    "\n",
    "        for j in range(len(data[i])):\n",
    "            #n=pings[i]\n",
    "\n",
    "            #print(n)\n",
    "            for z in range(0,n,int(window)):\n",
    "                #if(z+window>n):break\n",
    "                #print(z,z+window)\n",
    "\n",
    "                #df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "                node=data[i][j].pkts\n",
    "                name=str(j)+\" \"+cases[i]\n",
    "                nodeWindow=node[(node[\"seq\"]<z+window) & (node[\"seq\"]>=z)]\n",
    "                nodeWindowP=nodeWindow[\"rtt\"]\n",
    "                d[\"count\"].append(nodeWindowP.count())\n",
    "                #Case without outliers\n",
    "                #Case with outliers\n",
    "                std=0\n",
    "                if (nodeWindowP.std()>10):\n",
    "                    std=1\n",
    "                    std=nodeWindowP.std()\n",
    "\n",
    "                d[\"std\"].append(std)\n",
    "                mean=nodeWindowP.mean()\n",
    "                #if(mean<1):print(mean)\n",
    "                d[\"mean\"].append(mean)\n",
    "                var=0\n",
    "                if (nodeWindowP.var()>var): var=nodeWindowP.var()\n",
    "                d[\"var\"].append(var)\n",
    "                d[\"label\"].append(cases[i])\n",
    "                d[\"hop\"].append(data[i][j].hop)\n",
    "                d[\"type\"].append(casesAccuracy[i])\n",
    "                d[\"outliers\"].append(getOutliers(nodeWindow)[\"rtt\"].count())\n",
    "                missing=window-nodeWindow.count()\n",
    "                d[\"node\"].append(data[i][j].ip)\n",
    "                mP=getPercentageMissingPackets(nodeWindow,window)\n",
    "                PL=0\n",
    "                if(mP>30):\n",
    "                    PL=1\n",
    "                    PL=mP\n",
    "                d[\"packet loss\"].append(mP)\n",
    "\n",
    "\n",
    "\n",
    "    stats=pd.DataFrame(d)\n",
    "\n",
    "    dataK=stats.drop([\n",
    "        \"label\",\n",
    "        \"mean\",\n",
    "        \"var\",\n",
    "        \"std\",\n",
    "        #\"packet loss\",\n",
    "        \"outliers\",\n",
    "        \"hop\",\n",
    "        \"count\",\n",
    "        \"node\",\n",
    "        #\"type\"\n",
    "    ],axis=1)\n",
    "    dataK=dataK.fillna(0)\n",
    "\n",
    "    #print(dataK)\n",
    "    correction=[]\n",
    "    correction_alt=[]\n",
    "    col=np.array(dataK[\"type\"])\n",
    "    dataK=dataK.drop([\"type\"],axis=1)\n",
    "    #Creating simple array to correct unsupervised learning\n",
    "    #NB as it is unsupervised could happen that the correction are inverted\n",
    "    for i in range(len(col)):\n",
    "        el=d[\"type\"][i]\n",
    "        if el==\"normal\":\n",
    "            correction.append(1)\n",
    "            correction_alt.append(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            correction.append(0)\n",
    "            correction_alt.append(1)\n",
    "\n",
    "\n",
    "    dataC=stats[\"label\"]\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(dataK)\n",
    "    labels = kmeans.predict(dataK)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels=accuracy_score_corrected(correction,labels)\n",
    "    predicted=[]\n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        if(labels[i]==1):\n",
    "            predicted.append(\"normal\")\n",
    "        else: predicted.append(\"BH\")\n",
    "\n",
    "    #print(len(predicted))\n",
    "    stats[\"predicted\"]=pd.Series(np.array(predicted))\n",
    "    stats[\"predicted number\"]=pd.Series(np.array(labels))\n",
    "    stats[\"correction number\"]=pd.Series(np.array(correction))\n",
    "    stats_csv=stats[[\n",
    "        \"label\",\n",
    "        \"type\",\n",
    "        \"predicted\",\n",
    "        \"packet loss\",\n",
    "        \"outliers\",\n",
    "        \"std\",\n",
    "        \"hop\",\n",
    "        \"node\",\n",
    "        \"mean\"\n",
    "\n",
    "\n",
    "          ]]\n",
    "    stats_csv.to_csv(\"results_kmeans.csv\", sep='\\t', encoding='utf-8')\n",
    "    stats.head()\n",
    "    net_results={\n",
    "       \"case\":[],\n",
    "        \"predicted\":[],\n",
    "        \"real\":[]\n",
    "    }\n",
    "    #print(stats[\"predicted number\"])\n",
    "    for case in range(len(cases)):\n",
    "        subset=stats[stats[\"label\"]==cases[case]]\n",
    "        mean_predicted=str(subset[\"predicted number\"].mean()*100)+\"% normal\"\n",
    "        net_results[\"case\"].append(cases[case])\n",
    "        net_results[\"predicted\"].append(mean_predicted)\n",
    "        net_results[\"real\"].append(casesAccuracy[case])\n",
    "\n",
    "\n",
    "\n",
    "    results=pd.DataFrame(net_results)\n",
    "    results.to_csv(\"results_network_kmeans.csv\", sep='\\t', encoding='utf-8')\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traces.csv', '1bh-6', 'normal', '1bh-7', 'rnd-1', '1gh-7', '1gh-9', '1gh-5', '1gh-6', '.directory', '1bh-9', '1bh-5', 'rnd-2', '1gh-3', '1bh-3']\n",
      "../cooja3-9nodes/traces/traces.csv\n",
      "False\n",
      "../cooja3-9nodes/traces/1bh-6\n",
      "True\n",
      "../cooja3-9nodes/traces/normal\n",
      "True\n",
      "../cooja3-9nodes/traces/1bh-7\n",
      "True\n",
      "../cooja3-9nodes/traces/rnd-1\n",
      "True\n",
      "../cooja3-9nodes/traces/1gh-7\n",
      "True\n",
      "../cooja3-9nodes/traces/1gh-9\n",
      "True\n",
      "../cooja3-9nodes/traces/1gh-5\n",
      "True\n",
      "../cooja3-9nodes/traces/1gh-6\n",
      "True\n",
      "../cooja3-9nodes/traces/.directory\n",
      "False\n",
      "../cooja3-9nodes/traces/1bh-9\n",
      "True\n",
      "../cooja3-9nodes/traces/1bh-5\n",
      "True\n",
      "../cooja3-9nodes/traces/rnd-2\n",
      "True\n",
      "../cooja3-9nodes/traces/1gh-3\n",
      "True\n",
      "../cooja3-9nodes/traces/1bh-3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "path='../cooja3-9nodes/traces/'\n",
    "#df=pd.read_csv(directory+\"/traces/traces.csv\", sep=',', encoding='utf-8')\n",
    "#print(directory+df[\"directory\"].values)\n",
    "#print(directory)\n",
    "#analyze_network(directory,df,200,50)\n",
    "dirs=os.listdir(path)\n",
    "print(dirs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
