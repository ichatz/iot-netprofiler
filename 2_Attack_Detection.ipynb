{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# IoT Netprofiler\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Luca Maiano - https://www.linkedin.com/in/lucamaiano/\n",
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Detection\n",
    "\n",
    "In this notebook we apply *learning algorithms* with the aim of detect attacks in an IoT network as accurately as possible. Particularly, we will focus on **supervised** and **unsupervised** algorithms. With this analysis, we want to compare the effectiveness of the following algorithms:\n",
    "1. K-Nearest Neighbor (KNN)\n",
    "2. Random Forests Classifier\n",
    "3. Support Vector Machines (SVM)\n",
    "5. Deep Neural Network Classifier \n",
    "6. K-Means\n",
    "\n",
    "All mentioned algorithms have been extensively used by *state of the art* solutions in order to solve **anomaly-detection** problems [2].\n",
    "\n",
    "## Metrics Identification\n",
    "\n",
    "Using the same approach of Yavuz et al. [1], in order to deal with an imbalanced dataset we use AUC-ROC together with the following metrics:\n",
    "1. \n",
    "$\n",
    "\\begin{align}\n",
    "Precision = \\frac{TP}{TP+FP}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "2. \n",
    "$\n",
    "\\begin{align}\n",
    "Recall = \\frac{TP}{TP+FN}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "3. \n",
    "$\n",
    "\\begin{align}\n",
    "F1 = 2\\frac{precision * recall}{precision+recall}\n",
    "\\end{align}\n",
    "$\n",
    "4. AUC-ROC. \n",
    "\n",
    "If the AUC-ROC is bigger than 0.5, it means that the model is better than random guessing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from lib.utils import trace_processing\n",
    "from lib.visualization import data_visualization\n",
    "from lib.analysis import trace_statistics\n",
    "from lib.analysis import trace_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start importing 2 sets of experiments:\n",
    "1. *9 nodes* examples containing grids and random topologies;\n",
    "2. *16 nodes* examples containing grids and random topologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_9_nodes = trace_processing.import_trace('data/experiments/cooja3-9nodes/traces/', 'traces.csv')\n",
    "exp_16_nodes = trace_processing.import_trace('data/experiments/cooja3-16nodes/traces/', 'traces.csv')\n",
    "\n",
    "experiments = exp_9_nodes + exp_16_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Attacked vs Normal Behaviour\n",
    "\n",
    "Now we import *features* and *normalize* the data to speedup the learning process. For this experiment, we consider just two classes:\n",
    "1. **Normal** behaviour (0) meaning that the entire network is not under attack;\n",
    "2. **Attacked** (1), i.e. an attack has been performed (Black Hole or Gray Hole)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>experiment</th>\n",
       "      <th>tr_time</th>\n",
       "      <th>pckt_count</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>hop</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>loss</th>\n",
       "      <th>outliers</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaa::212:7404:4:404:</td>\n",
       "      <td>16nodes/grid_normal_2019-02-26_11:48_</td>\n",
       "      <td>0.276714</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.402463</td>\n",
       "      <td>0.407981</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.233569</td>\n",
       "      <td>0.612539</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaa::212:7408:8:808:</td>\n",
       "      <td>9nodes/grid9_normal_2019-02-13_17:05_</td>\n",
       "      <td>0.621075</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.601773</td>\n",
       "      <td>0.154327</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.516164</td>\n",
       "      <td>0.651923</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaa::212:7407:7:707:</td>\n",
       "      <td>16nodes/grid_1gh50-9_2019-02-19_23:54_</td>\n",
       "      <td>0.765470</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.427156</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>0.550957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaa::212:7404:4:404:</td>\n",
       "      <td>9nodes/rnd2_1bh-8_2019-02-15_17:28_</td>\n",
       "      <td>0.655860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210058</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.286983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaa::212:7403:3:303:</td>\n",
       "      <td>9nodes/grid9_1bh-9_2019-02-13_15:57_</td>\n",
       "      <td>0.611601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143371</td>\n",
       "      <td>0.068582</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.099969</td>\n",
       "      <td>0.219303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    node                              experiment   tr_time  \\\n",
       "0  aaaa::212:7404:4:404:   16nodes/grid_normal_2019-02-26_11:48_  0.276714   \n",
       "1  aaaa::212:7408:8:808:   9nodes/grid9_normal_2019-02-13_17:05_  0.621075   \n",
       "2  aaaa::212:7407:7:707:  16nodes/grid_1gh50-9_2019-02-19_23:54_  0.765470   \n",
       "3  aaaa::212:7404:4:404:     9nodes/rnd2_1bh-8_2019-02-15_17:28_  0.655860   \n",
       "4  aaaa::212:7403:3:303:    9nodes/grid9_1bh-9_2019-02-13_15:57_  0.611601   \n",
       "\n",
       "   pckt_count      mean       var   hop       min       max      loss  \\\n",
       "0    0.347826  0.402463  0.407981  0.00  0.233569  0.612539  0.652174   \n",
       "1    0.673913  0.601773  0.154327  0.75  0.516164  0.651923  0.326087   \n",
       "2    0.956522  0.427156  0.138889  0.25  0.373390  0.550957  0.043478   \n",
       "3    1.000000  0.210058  0.042219  0.25  0.215190  0.286983  0.000000   \n",
       "4    1.000000  0.143371  0.068582  0.00  0.099969  0.219303  0.000000   \n",
       "\n",
       "   outliers  label  \n",
       "0  0.076923      0  \n",
       "1  0.076923      0  \n",
       "2  0.153846      1  \n",
       "3  0.000000      1  \n",
       "4  0.000000      1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = None\n",
    "n_classes = 2\n",
    "\n",
    "for experiment in experiments:\n",
    "    label = 0\n",
    "    topology = experiment[0].split('/')[2].split('cooja3-')[1]\n",
    "    experiment_id = topology + '/' + experiment[1]\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Assign a label\n",
    "        if experiment[1].find('gh') >= 0 or experiment[1].find('bh') >= 0:\n",
    "            label = 1\n",
    "    else:\n",
    "        # Assign a label\n",
    "        if experiment[1].find('gh') >= 0:\n",
    "            label = 1\n",
    "        elif experiment[1].find('bh') >= 0:\n",
    "            label = 2\n",
    "    nodes, packets_node = trace_processing.process_cooja_traces(experiment[0], experiment[1])\n",
    "    \n",
    "    if data is None:\n",
    "        data = trace_processing.feature_extraction(nodes, packets_node, label, experiment_id, log_transform=True, window_size=48)    \n",
    "    else:\n",
    "        data = pd.concat([data, trace_processing.feature_extraction(nodes, packets_node, label, experiment_id, log_transform=True, window_size=48)])\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "norm_data = trace_processing.feature_normalization(data, ['node', 'experiment', 'label'])\n",
    "norm_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the dataset in *training and testing set* of size 80% and 20% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr_time</th>\n",
       "      <th>pckt_count</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>hop</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>loss</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276714</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.402463</td>\n",
       "      <td>0.407981</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.233569</td>\n",
       "      <td>0.612539</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.621075</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.601773</td>\n",
       "      <td>0.154327</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.516164</td>\n",
       "      <td>0.651923</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.765470</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.427156</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.373390</td>\n",
       "      <td>0.550957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.655860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210058</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.286983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143371</td>\n",
       "      <td>0.068582</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.099969</td>\n",
       "      <td>0.219303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tr_time  pckt_count      mean       var   hop       min       max  \\\n",
       "0  0.276714    0.347826  0.402463  0.407981  0.00  0.233569  0.612539   \n",
       "1  0.621075    0.673913  0.601773  0.154327  0.75  0.516164  0.651923   \n",
       "2  0.765470    0.956522  0.427156  0.138889  0.25  0.373390  0.550957   \n",
       "3  0.655860    1.000000  0.210058  0.042219  0.25  0.215190  0.286983   \n",
       "4  0.611601    1.000000  0.143371  0.068582  0.00  0.099969  0.219303   \n",
       "\n",
       "       loss  outliers  \n",
       "0  0.652174  0.076923  \n",
       "1  0.326087  0.076923  \n",
       "2  0.043478  0.153846  \n",
       "3  0.000000  0.000000  \n",
       "4  0.000000  0.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = norm_data.drop(['node', 'experiment', 'label'], axis=1)\n",
    "y = norm_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Starting from the results that we obtained during the data exploration phase, we can now start to train and compare the learning algorithms. The results will be compared with different sets of features. Features will be iteratively selected removing the most relevant and less relevant feature. Most significant feature is dropped to avoid *overfitting*, less relevant feature is dropped to avoid *underfitting*.\n",
    "\n",
    "The experiment will be repeated iteratively following this way:\n",
    "1. select a set of feature;\n",
    "2. run learning algorithms;\n",
    "3. measure performances.\n",
    "\n",
    "At the end the best set of features will be selected. We start selecting the entire set of features.\n",
    "\n",
    "### Supervised Algorithms\n",
    "\n",
    "1. The first algorithm that we evaluate is **k-NN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on validation set 1/5: 0.6589068825910931\n",
      "AUC on validation set 2/5: 0.6892712550607287\n",
      "AUC on validation set 3/5: 0.6503036437246963\n",
      "AUC on validation set 4/5: 0.7036466966611413\n",
      "AUC on validation set 5/5: 0.6953982161180835\n",
      "Mean AUC 0.680 (Std +/- 0.021)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>auc roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.755708</td>\n",
       "      <td>0.662544</td>\n",
       "      <td>0.670081</td>\n",
       "      <td>0.665994</td>\n",
       "      <td>0.670081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall  f1-score   auc roc\n",
       "0   knn  0.755708   0.662544  0.670081  0.665994  0.670081"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred = trace_classification.k_nn_classifier(X_train, y_train, X_test, y_test, n_neighbors=3, cross_val=5)\n",
    "knn_results, knn_confusion_matrix = trace_classification.test_metrics('knn', y_test, knn_pred)\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now we evaluate **RandomForest Classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on validation set 1/5: 0.7001518218623481\n",
      "AUC on validation set 2/5: 0.6991396761133603\n",
      "AUC on validation set 3/5: 0.6573886639676114\n",
      "AUC on validation set 4/5: 0.6943918225590023\n",
      "AUC on validation set 5/5: 0.7036466966611413\n",
      "Mean AUC 0.704 (Std +/- 0.000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>auc roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.792237</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.687062</td>\n",
       "      <td>0.695357</td>\n",
       "      <td>0.687062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  accuracy  precision    recall  f1-score   auc roc\n",
       "0  random forest  0.792237     0.7064  0.687062  0.695357  0.687062"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pred = trace_classification.random_forest_classifier(X_train, y_train, X_test, y_test, n_estimators=100, cross_val=5)\n",
    "rfc_results, rfc_confusion_matrix = trace_classification.test_metrics('random forest', y_test, rfc_pred)\n",
    "rfc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prediction of **Support Vector Machines (SVM)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on validation set 1/5: 0.6088056680161944\n",
      "AUC on validation set 2/5: 0.5199898785425102\n",
      "AUC on validation set 3/5: 0.6260121457489878\n",
      "AUC on validation set 4/5: 0.5800378877575183\n",
      "AUC on validation set 5/5: 0.6135646065198517\n",
      "Mean AUC 0.590 (Std +/- 0.038)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>auc roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.788294</td>\n",
       "      <td>0.615546</td>\n",
       "      <td>0.63442</td>\n",
       "      <td>0.615546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall  f1-score   auc roc\n",
       "0   svm  0.808219   0.788294  0.615546   0.63442  0.615546"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred = trace_classification.svm_classifier(X_train, y_train, X_test, y_test, kernel='linear', cross_val=5)\n",
    "svm_results, svm_confusion_matrix = trace_classification.test_metrics('svm', y_test, svm_pred)\n",
    "svm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finally we implement **Deep Neural Networks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = trace_classification.neural_net_classifier(X_train, y_train, X_test, y_test, '2classes_ATCK_NORM_48pckts')\n",
    "nn_results, nn_confusion_matrix = trace_classification.test_metrics('neural network', y_test, nn_pred)\n",
    "nn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Algorithms\n",
    "\n",
    "Now we can try to model the problem as an unsupervised learning problem. First, we apply a PCA transformation to collapse the set of datapoints to a 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = trace_classification.pca_transformation(X, n_components=len(X.columns))\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Let us try modeling the problem with **K-Means**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pred, centroids = trace_classification.kmeans_classifier(X_pca, n_clusters=2)\n",
    "data_visualization.plot_3d_points(X_pca[0], X_pca[1], X_pca[3], y, plot_name='KMeans_K2_48pckts', centroids=centroids)\n",
    "kmeans_results, kmeans_confusion_matrix = trace_classification.test_metrics('kmeans', y, kmeans_pred)\n",
    "kmeans_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Let us compare the results obtained from the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_classification.write_results([knn_results, rfc_results, svm_results, nn_results, kmeans_results], list(X.columns.values), 'ATCK_NORM_48pckts', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the table above, we see that the **neural network** outperform all the other models. **KNN** also achieve really good results follwed by *random forsests*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Normal Behaviour vs Grey Hole vs Black Hole Attack\n",
    "\n",
    "For this second scenario, we want to detect which attack has been performed (if any). Each node will be labeled as follows:\n",
    "1. **Normal** behaviour (0) meaning that the entire network is not under attack;\n",
    "2. **Grey Hole** (1);\n",
    "3. **Black Hole** (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "n_classes = 3\n",
    "\n",
    "for experiment in experiments:\n",
    "    label = 0\n",
    "    topology = experiment[0].split('/')[2].split('cooja3-')[1]\n",
    "    experiment_id = topology + '/' + experiment[1]\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Assign a label\n",
    "        if experiment[1].find('gh') >= 0 or experiment[1].find('bh') >= 0:\n",
    "            label = 1\n",
    "    else:\n",
    "        # Assign a label\n",
    "        if experiment[1].find('gh') >= 0:\n",
    "            label = 1\n",
    "        elif experiment[1].find('bh') >= 0:\n",
    "            label = 2\n",
    "    nodes, packets_node = trace_processing.process_cooja_traces(experiment[0], experiment[1])\n",
    "    \n",
    "    if data is None:\n",
    "        data = trace_processing.feature_extraction(nodes, packets_node, label, experiment_id, log_transform=True, window_size=48)    \n",
    "    else:\n",
    "        data = pd.concat([data, trace_processing.feature_extraction(nodes, packets_node, label, experiment_id, log_transform=True, window_size=48)])\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "norm_data = trace_processing.feature_normalization(data, ['node', 'experiment', 'label'])\n",
    "\n",
    "# Normalize data\n",
    "X = norm_data.drop(['node', 'experiment', 'label'], axis=1)\n",
    "y = norm_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test\n",
    "\n",
    "norm_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We repeat the experiment following the same identical approach as before. Thus we choose a set of features, and we iterate removing the most important and less importan one until we obtain the best results.\n",
    "\n",
    "### Supervised Algorithms\n",
    "\n",
    "1. The first algorithm that we evaluate is **k-NN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = trace_classification.k_nn_classifier(X_train, y_train, X_test, y_test, n_neighbors=3, cross_val=5)\n",
    "knn_results, knn_confusion_matrix = trace_classification.test_metrics('knn', y_test, knn_pred)\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now we evaluate **RandomForest Classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = trace_classification.random_forest_classifier(X_train, y_train, X_test, y_test, n_estimators=100, cross_val=5)\n",
    "rfc_results, rfc_confusion_matrix = trace_classification.test_metrics('random forest', y_test, rfc_pred)\n",
    "rfc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prediction of **Support Vector Machines (SVM)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = trace_classification.svm_classifier(X_train, y_train, X_test, y_test, kernel='linear', cross_val=5)\n",
    "svm_results, svm_confusion_matrix = trace_classification.test_metrics('svm', y_test, svm_pred)\n",
    "svm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finally we implement **Deep Neural Networks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = trace_classification.neural_net_classifier(X_train, y_train, X_test, y_test, '3classes_BH_GH_NORM_48pckts')\n",
    "nn_results, nn_confusion_matrix = trace_classification.test_metrics('neural network', y_test, nn_pred)\n",
    "nn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Algorithms\n",
    "\n",
    "Now we can try to model the problem as an unsupervised learning problem. First, we apply a PCA transformation to collapse the set of datapoints to a 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = trace_classification.pca_transformation(X, n_components=len(X.columns))\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Let us try modeling the problem with **K-Means**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pred, centroids = trace_classification.kmeans_classifier(X_pca, n_clusters=3)\n",
    "data_visualization.plot_3d_points(X_pca[0], X_pca[1], X_pca[3], y, plot_name='KMeans_K3_48pckts', centroids=centroids)\n",
    "kmeans_results, kmeans_confusion_matrix = trace_classification.test_metrics('kmeans', y, kmeans_pred)\n",
    "kmeans_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Let us compare the results obtained from the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_classification.write_results([knn_results, rfc_results, svm_results, nn_results, kmeans_results], list(X.columns.values), 'BH_GH_NORM_48pckts', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the **neural network** still performs good, folloed by **svm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. *Deep Learning for Detection of Routing Attacks in the Internet of Things*, International Journal of Computational Intelligence Systems (2018), by Furkan Yusuf Yavuz, Devrim UÌˆnal and Ensar Gul\n",
    "2. *Machine Learning in IoT Security:Current Solutions and Future Challenges*, arXiv:1904.05735v1 (Mar 2019), by Fatima Hussain, Rasheed Hussain, Syed Ali Hassan, and Ekram Hossain.\n",
    "3. *Almost Everything You Need to Know About Time Series*, https://towardsdatascience.com/almost-everything-you-need-to-know-about-time-series-860241bdc578, by Marco Peixeiro\n",
    "4. *How to Check if Time Series Data is Stationary with Python*, https://machinelearningmastery.com/time-series-data-stationary-python/, by Jason Brownlee\n",
    "5. *K-Means Clustering in Python*, https://mubaris.com/posts/kmeans-clustering/, by Mubaris NK\n",
    "6. *AUC ROC Curve Scoring Function for Multi-class Classification*, https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659, by Eric Plog"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
